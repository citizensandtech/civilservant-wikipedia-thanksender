{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "1. Implement the data described in this [google doc](https://docs.google.com/document/d/1plhoDbQryYQ32vZMXu8YmlLSp30QTdup43k6uTePOT4/edit#heading=h.b2ilq31no707).\n",
    "1. One thankee per row, everyone who was ever inputted into the thanker app. Items that were experiment id -3\n",
    "    1. We need all the actions connected to thos (where they are the object, maybe in metadatajson)\n",
    "        1. Error status of those\n",
    "1. Survey results from julia\n",
    "1. Then need replica data on behaviour (with caching probably).\n",
    "\n",
    "## Note\n",
    "1. the thanker final data collector was written in the edit-sync repo as part of onboard_thankers. I'm switching it up because this is closer to the goal of making a dataCollector module for civilservant2.0\n",
    "\n",
    "### connections\n",
    "1. connecting to aws studies mysql on `3311`\n",
    "    1. `ssh -N studies.cs 3311:localhost:3306`\n",
    "2. connecting to wmf repliacs on `3310`\n",
    "    1. `ssh -N maximilianklein@tools-login.wmflabs.org -L 3310:enwiki.analytics.db.svc.eqiad.wmflabs:3306`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from civilservant.models.core import ExperimentThing, ExperimentAction\n",
    "from thanks.utils import _get_experiment_id\n",
    "from civilservant.util import read_config_file\n",
    "import os\n",
    "from civilservant.db import init_session, init_engine\n",
    "from sqlalchemy.dialects import mysql\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# import uuid\n",
    "CACHEDIR='/data/project/cache'\n",
    "TRESORDIR='/home/paprika/Tresors/CivilServant/projects/wikipedia-integration/gratitude-study/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(CACHEDIR, 'thankee-misc', 'survey_and_thankee_actions.pickle'))\n",
    "acct_map = pd.read_pickle(os.path.join(CACHEDIR, 'thankee-misc', 'acct_map.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove en accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['lang']=='en'].shape\n",
    "df = df[df['lang']!='en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assign behavioral_obs_start_dt \n",
    "1. based on first_thank_dt or that of block partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_block_id = df['randomization_block_id']>=0\n",
    "non_null_thank_dt = pd.notnull(df['first_thank_dt'])\n",
    "\n",
    "block_thank_rel = df[(positive_block_id) & (non_null_thank_dt)][['randomization_block_id', 'first_thank_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_first_thank = block_thank_rel.set_index('randomization_block_id').to_dict()['first_thank_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_start_dt(row):\n",
    "    # if we have a thank date use that\n",
    "    if pd.notnull(row.loc['first_thank_dt']):\n",
    "        return row.loc['first_thank_dt']\n",
    "    # otherwise do they have a block partner with a first thank date\n",
    "    else:\n",
    "        try:\n",
    "            return block_first_thank[row.loc['randomization_block_id']]\n",
    "        # fallback onto the ET created date\n",
    "        except KeyError:\n",
    "            return row.loc['created_dt']\n",
    "\n",
    "df['behavior_start_dt'] = df.apply(lambda row: get_behavior_start_dt(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any(pd.isnull(df['behavior_start_dt'])) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting external data\n",
    "\n",
    "1. labor.hours.per.day.diff \n",
    "    1. participants$labor.hours.per.day.post.treatment -participants$labor.hours.per.day.pre.treatment\n",
    "    2. 42 days before and after the thank\n",
    "2. two.week.retention\n",
    "    1. Whether an account made an edit any-namespace between day 8 and 42 after they received a thank\n",
    "3. thanks.sent\n",
    "    1. count variable indicating the number of thanks sent by this account to other Wikipedians in the 42 day period after receiving the intervention.\n",
    "4. registration date\n",
    "    1. account age at created_dt\n",
    "    1. account age at first_thank_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from civilservant.wikipedia.queries.revisions import get_timestamps_within_range\n",
    "from civilservant.wikipedia.queries.user_interactions import get_thanks_sending\n",
    "from civilservant.wikipedia.queries.users import get_user_basic_data, get_user_disablemail_property\n",
    "from civilservant.wikipedia.utils import make_cached_df, make_sessions, calc_labour_hours,\\\n",
    "                                            to_wmftimestamp, from_wmftimestamp, bin_from_td\n",
    "from civilservant.wikipedia.connections.database import make_wmf_con\n",
    "\n",
    "wmf_con = make_wmf_con()\n",
    "\n",
    "LABOR_HOURS_OBS_WINDOW = datetime.timedelta(days=42)\n",
    "\n",
    "@make_cached_df('grat-thankee-timestamps')\n",
    "def get_user_edits_before_and_after_obs(lang, user_name, thank_date):\n",
    "    start_date = thank_date - LABOR_HOURS_OBS_WINDOW\n",
    "    end_date = thank_date + LABOR_HOURS_OBS_WINDOW\n",
    "    ts = get_timestamps_within_range(lang=lang, start_date=start_date, end_date=end_date, user_name=user_name,\n",
    "                         con=wmf_con)\n",
    "    return ts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frem length: 15558\n"
     ]
    }
   ],
   "source": [
    "# delete this for full run\n",
    "# df = df[:1000]\n",
    "print(f'data frem length: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_hours_ts_df'] = df.apply(lambda row: get_user_edits_before_and_after_obs(row['lang'],\n",
    "                                                                                  row['user_name'],\n",
    "                                                                                  row['behavior_start_dt'])\n",
    "                                                                                   , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labor_hours(before_after, behavior_start_dt, ts_df):\n",
    "    start_dt = behavior_start_dt - LABOR_HOURS_OBS_WINDOW if before_after=='before' else behavior_start_dt\n",
    "    end_dt = behavior_start_dt if before_after=='before' else behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    \n",
    "    window_ts_df =  ts_df[(ts_df['rev_timestamp'] > start_dt)  & (ts_df['rev_timestamp'] <= end_dt)]\n",
    "    if len(window_ts_df)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        window_dts = [pd.to_datetime(np_dt) for np_dt in window_ts_df['rev_timestamp'].values]\n",
    "        window_labor_hours = calc_labour_hours(window_dts)\n",
    "        return window_labor_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_hours_pre_treatment'] = df.apply(lambda row: num_labor_hours('before', \n",
    "                                                                row['behavior_start_dt'],\n",
    "                                                                row['labor_hours_ts_df']),\n",
    "                                    axis=1)\n",
    "df['labor_hours_post_treatment'] = df.apply(lambda row: num_labor_hours('after', \n",
    "                                                                row['behavior_start_dt'],\n",
    "                                                                row['labor_hours_ts_df']),\n",
    "                                    axis=1)\n",
    "\n",
    "df['labor_hours_per_day_pre_treatment'] = df['labor_hours_pre_treatment'] / LABOR_HOURS_OBS_WINDOW.days\n",
    "df['labor_hours_per_day_post_treatment'] = df['labor_hours_post_treatment'] / LABOR_HOURS_OBS_WINDOW.days\n",
    "df['labor_hours_per_day_diff'] = df['labor_hours_per_day_post_treatment'] - df['labor_hours_per_day_pre_treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006395494993643856"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labor_hours_per_day_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_week_retention(behavior_start_dt, ts_df):\n",
    "    start_dt = behavior_start_dt + datetime.timedelta(days=7)\n",
    "    end_dt = behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    \n",
    "    window_ts_df =  ts_df[(ts_df['rev_timestamp'] > start_dt)  & (ts_df['rev_timestamp'] <= end_dt)]\n",
    "    return True if len(window_ts_df)>0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['two_week_retention'] = df.apply(lambda row: two_week_retention(row['behavior_start_dt'],\n",
    "                                                                   row['labor_hours_ts_df']),\n",
    "                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24887517675793805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['two_week_retention'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankees-thanks-sent')\n",
    "def get_subsequent_thanks_sent(lang, user_name, behavior_start_dt):\n",
    "    start_dt = behavior_start_dt\n",
    "    end_dt = behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    thanks_sent = get_thanks_sending(lang, user_name, start_dt, end_dt, wmf_con)\n",
    "    return thanks_sent\n",
    "# @make_cached_df('grat-thankees-thanks-sent-pre-treatment')\n",
    "# def get_antecedent_thanks_sent(lang, user_name, behavior_start_dt):\n",
    "#     start_dt = behavior_start_dt - LABOR_HOURS_OBS_WINDOW\n",
    "#     end_dt = behavior_start_dt\n",
    "#     thanks_sent = get_thanks_sending(lang, user_name, start_dt, end_dt, wmf_con)\n",
    "#     return thanks_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thanks_sent_df'] = df.apply(lambda row: get_subsequent_thanks_sent(row['lang'],\n",
    "                                                                    row['user_name'],\n",
    "                                                                    row['behavior_start_dt'],                                                                   ),\n",
    "                                    axis=1)\n",
    "df['thanks_sent'] = df['thanks_sent_df'].apply(len)\n",
    "\n",
    "# df['thanks_sent_df_pre_treatment'] = df.apply(lambda row: get_antecedent_thanks_sent(row['lang'],\n",
    "#                                                                     row['user_name'],\n",
    "#                                                                     row['behavior_start_dt'],                                                                   ),\n",
    "#                                     axis=1)\n",
    "# df['thanks_sent_pre_treatment'] = df['thanks_sent_df_pre_treatment'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16460984702403908"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thanks_sent'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thanks sent pre sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thanks_sent_pre_treatment'] = df['metadata_json'].apply(lambda d: d['sync_object']['num_prev_thanks_pre_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.013947808201569"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thanks_sent_pre_treatment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankee-user-basic-data')\n",
    "def get_user_basic(lang, user_name):\n",
    "    return get_user_basic_data(lang=lang, user_name=user_name, wmf_con=wmf_con)\n",
    "\n",
    "def user_registration_dt_from_basic(user_basic_df):\n",
    "    return user_basic_df['user_registration'].iloc[0] if len(user_basic_df)>0 else float('nan')\n",
    "\n",
    "def user_id_from_basic(user_basic_df):\n",
    "    return user_basic_df['user_id'].iloc[0] if len(user_basic_df)>0 else float('nan')\n",
    "\n",
    "def account_age_at_assignment(created_dt, registration_dt):\n",
    "    return bin_from_td(created_dt-registration_dt) if pd.notnull(registration_dt) else 'bin_deleted'\n",
    "\n",
    "def account_age_at_treatment(behavior_start_dt, registration_dt):\n",
    "    return bin_from_td(behavior_start_dt-registration_dt) if pd.notnull(registration_dt) else 'bin_deleted'\n",
    "\n",
    "def year(registration_dt):\n",
    "    return registration_dt.year if pd.notnull(registration_dt) else registration_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_basic_data'] = df.apply(lambda row: get_user_basic(row['lang'], row['user_name']), axis=1)\n",
    "df['user_registration_dt'] = df['user_basic_data'].apply(user_registration_dt_from_basic)\n",
    "\n",
    "df['user_id'] = df['user_basic_data'].apply(user_id_from_basic)\n",
    "\n",
    "df['user_registration_dt_sync_object'] = df['metadata_json'].apply(lambda d: datetime.datetime.fromisoformat(d['sync_object']['user_registration']))\n",
    "df['created_dt_sync_object'] = df['metadata_json'].apply(lambda d: datetime.datetime.fromisoformat(d['sync_object']['created_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_experience_assignment'] = df['metadata_json'].apply(lambda d: f\"bin_{d['sync_object']['user_experience_level']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_experience_assignment_post_candidate'] = df.apply(lambda row: account_age_at_assignment(row['created_dt_sync_object'], row['user_registration_dt']) ,axis=1)\n",
    "# df['prev_experience_assignment'] = df.apply(lambda row: account_age_at_assignment(row['created_dt'], row['user_registration_dt']) ,axis=1)\n",
    "df['prev_experience_treatment'] = df.apply(lambda row: account_age_at_assignment(row['behavior_start_dt'], row['user_registration_dt']) ,axis=1)\n",
    "\n",
    "df['year'] = df['user_registration_dt'].apply(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if calculated registration_dates match original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df562 = df[df['randomization_block_id']==562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_registration_dt</th>\n",
       "      <th>user_registration_dt_sync_object</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>created_dt_sync_object</th>\n",
       "      <th>prev_experience_assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>2019-05-21 06:45:31</td>\n",
       "      <td>2019-05-21 06:45:31</td>\n",
       "      <td>2019-09-06 18:36:26</td>\n",
       "      <td>2019-07-30 09:06:58</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4871</td>\n",
       "      <td>2019-06-24 11:12:07</td>\n",
       "      <td>2019-06-24 11:12:07</td>\n",
       "      <td>2019-07-30 23:51:00</td>\n",
       "      <td>2019-07-30 09:07:08</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_registration_dt user_registration_dt_sync_object  \\\n",
       "4070  2019-05-21 06:45:31              2019-05-21 06:45:31   \n",
       "4871  2019-06-24 11:12:07              2019-06-24 11:12:07   \n",
       "\n",
       "              created_dt created_dt_sync_object prev_experience_assignment  \n",
       "4070 2019-09-06 18:36:26    2019-07-30 09:06:58                      bin_0  \n",
       "4871 2019-07-30 23:51:00    2019-07-30 09:07:08                      bin_0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df562[['user_registration_dt', 'user_registration_dt_sync_object', 'created_dt', 'created_dt_sync_object', 'prev_experience_assignment']] # looks like what  we have in the sync_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankee-has-email')\n",
    "def get_has_disablemail_df(lang, user_id):\n",
    "    disablemail_df = get_user_disablemail_property(lang, user_id, wmf_con=wmf_con)\n",
    "    return disablemail_df # True if they havent disabled, otherwise they have disabled and dont get email\n",
    "    \n",
    "def get_has_email(lang, user_id):\n",
    "    if pd.isnull(user_id):\n",
    "        return user_id\n",
    "    else:\n",
    "        disablemail_df = get_has_disablemail_df(lang, user_id)\n",
    "        return True if len(disablemail_df)==0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_email'] = df.apply(lambda row: get_has_email(row['lang'], row['user_id']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compliance - app\n",
    "1. noncompliant if don't have a user_registration_date\n",
    "2. block partners of removed users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-22 00:00:00    1450\n",
       "2019-10-25 00:00:00    1288\n",
       "2019-09-23 18:10:00     781\n",
       "2019-09-23 23:14:52     291\n",
       "2019-11-15 00:00:00      91\n",
       "2019-10-30 00:00:00      86\n",
       "2020-02-06 00:00:00      51\n",
       "2019-08-31 20:45:52       7\n",
       "2020-01-13 16:04:01       1\n",
       "Name: removed_dt, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['removed_dt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 47)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['first_thank_dt']<datetime.datetime(2019, 9, 23)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thanks_not_received_skipped']  = (pd.isnull(df['first_thank_dt'])) & (df['num_skips'] > 0) \n",
    "df['thanks_not_received_not_seen'] = (pd.isnull(df['first_thank_dt'])) & (df['num_skips']==0) & (df['num_errors']==0)\n",
    "df['thanks_not_received_error']  = (pd.isnull(df['first_thank_dt'])) & (df['num_errors'] > 0)\n",
    "df['thanks_not_received_user_deleted'] = df['user_basic_data'].apply(len) == 0\n",
    "df['received_multiple_thanks'] = df['num_thanks'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complier_app_any_reason'] = ~(df['thanks_not_received_skipped'] | df['thanks_not_received_not_seen'] | df['thanks_not_received_error'] | df['thanks_not_received_user_deleted'] | df['received_multiple_thanks'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4950]['num_skips']> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.isnull(df.iloc[4950]['first_thank_dt'])) & (df.iloc[4950]['num_skips'] == 0) & (df.iloc[4950]['num_errors']==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compliance Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complier'] = pd.notnull(df['wikipedians.value.contributions']) & pd.notnull(df['community.friendly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_COLS = [\n",
    "'private.anonymous.id',\n",
    "'randomization.block.id',\n",
    "'labor.hours.per.day.diff', \n",
    "'two.week.retention',\n",
    "'thanks.sent',\n",
    "'thanks.sent.pre.treatment',\n",
    "'wikipedians.value.contributions',\n",
    "'community.friendly',\n",
    "'complier',\n",
    "'lang',\n",
    "'prev.experience.assignment',\n",
    "'prev.experience.treatment',\n",
    "'year',\n",
    "'has.email',\n",
    "'remembered.thanks',\n",
    "'overall.exp',    \n",
    "'social.value.1',    \n",
    "'social.value.3',    \n",
    "'social.value.4',    \n",
    "'social.warmth.2',    \n",
    "'social.warmth.3',    \n",
    "'randomization.arm',\n",
    "'number.thanks.received',\n",
    "'number.skips.received',\n",
    "'thanks.not.received.skipped',\n",
    "'thanks.not.received.not.seen',\n",
    "'thanks.not.received.error',\n",
    "'thanks.not.received.user.deleted',\n",
    "'received.multiple.thanks', \n",
    "'complier.app.any.reason',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_dt', 'randomization_arm', 'randomization_condition',\n",
       "       'removed_dt', 'metadata_json', 'lang', 'user_name',\n",
       "       'randomization_block_id', 'num_errors', 'num_skips', 'first_thank_dt',\n",
       "       'num_thanks', 'num_messages', 'consent', 'overall.exp',\n",
       "       'social.value.1', 'wikipedians.value.contributions', 'social.value.3',\n",
       "       'social.value.4', 'community.friendly', 'social.warmth.2',\n",
       "       'social.warmth.3', 'community', 'remembered.thanks',\n",
       "       'private_anonymous_id', 'behavior_start_dt', 'labor_hours_ts_df',\n",
       "       'labor_hours_pre_treatment', 'labor_hours_post_treatment',\n",
       "       'labor_hours_per_day_pre_treatment',\n",
       "       'labor_hours_per_day_post_treatment', 'labor_hours_per_day_diff',\n",
       "       'two_week_retention', 'thanks_sent_df', 'thanks_sent',\n",
       "       'thanks_sent_df_pre_treatment', 'thanks_sent_pre_treatment',\n",
       "       'user_basic_data', 'user_registration_dt', 'user_id',\n",
       "       'user_registration_dt_sync_object', 'created_dt_sync_object',\n",
       "       'prev_experience_assignment',\n",
       "       'prev_experience_assignment_post_candidate',\n",
       "       'prev_experience_treatment', 'year', 'has_email',\n",
       "       'thanks_not_received_skipped', 'thanks_not_received_not_seen',\n",
       "       'thanks_not_received_error', 'thanks_not_received_user_deleted',\n",
       "       'received_multiple_thanks', 'complier_app_any_reason', 'complier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_col_names = [cname.replace('_','.') for cname in df.columns]\n",
    "df.columns = r_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rename = {'num.skips':'number.skips.received',\n",
    "             'num.thanks':'number.thanks.received'}\n",
    "df = df.rename(columns=col_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_col_present = [oc in df.columns for oc in OUTPUT_COLS]\n",
    "all(output_col_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('private.anonymous.id', True),\n",
       " ('randomization.block.id', True),\n",
       " ('labor.hours.per.day.diff', True),\n",
       " ('two.week.retention', True),\n",
       " ('thanks.sent', True),\n",
       " ('thanks.sent.pre.treatment', True),\n",
       " ('wikipedians.value.contributions', True),\n",
       " ('community.friendly', True),\n",
       " ('complier', True),\n",
       " ('lang', True),\n",
       " ('prev.experience.assignment', True),\n",
       " ('prev.experience.treatment', True),\n",
       " ('year', True),\n",
       " ('has.email', True),\n",
       " ('remembered.thanks', True),\n",
       " ('overall.exp', True),\n",
       " ('social.value.1', True),\n",
       " ('social.value.3', True),\n",
       " ('social.value.4', True),\n",
       " ('social.warmth.2', True),\n",
       " ('social.warmth.3', True),\n",
       " ('randomization.arm', True),\n",
       " ('number.thanks.received', True),\n",
       " ('number.skips.received', True),\n",
       " ('thanks.not.received.skipped', True),\n",
       " ('thanks.not.received.not.seen', True),\n",
       " ('thanks.not.received.error', True),\n",
       " ('thanks.not.received.user.deleted', True),\n",
       " ('received.multiple.thanks', True),\n",
       " ('complier.app.any.reason', True)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(OUTPUT_COLS, output_col_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Data Drills'\t'research materials'\t    thanks_love_counts_2017\r\n",
      " datasets\t thankable_revisions_task   thanks-love-records-07.2018\r\n",
      "'gdpr notices'\t thanker_surveys\r\n",
      " report-drafts\t thanking_paper_prototype\r\n"
     ]
    }
   ],
   "source": [
    "!ls $TRESORDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'Data Drills/thankee/post_experiment_analysis'\n",
    "out_fname = 'grat-thankee-all-pre-post-treatment-vars.csv'\n",
    "out_extracols_fname = 'grat-thankee-all-pre-post-treatment-vars-max-cols.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_map.to_csv(os.path.join(TRESORDIR, out_dir,'acct_map.csv'), index=False)\n",
    "df[OUTPUT_COLS].to_csv(os.path.join(TRESORDIR, out_dir, out_fname), index=False)\n",
    "df.to_csv(os.path.join(TRESORDIR, out_dir, out_extracols_fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380      False\n",
       "1193     False\n",
       "1283     False\n",
       "1286     False\n",
       "1296     False\n",
       "         ...  \n",
       "14906    False\n",
       "15216    False\n",
       "15244    False\n",
       "15688    False\n",
       "15925    False\n",
       "Name: two.week.retention, Length: 62, dtype: bool"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['thanks.not.received.user.deleted']]['two.week.retention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['received.multiple.thanks']]['randomization.block.id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
