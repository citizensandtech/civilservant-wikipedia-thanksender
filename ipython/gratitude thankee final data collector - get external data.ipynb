{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "1. Implement the data described in this [google doc](https://docs.google.com/document/d/1plhoDbQryYQ32vZMXu8YmlLSp30QTdup43k6uTePOT4/edit#heading=h.b2ilq31no707).\n",
    "1. One thankee per row, everyone who was ever inputted into the thanker app. Items that were experiment id -3\n",
    "    1. We need all the actions connected to thos (where they are the object, maybe in metadatajson)\n",
    "        1. Error status of those\n",
    "1. Survey results from julia\n",
    "1. Then need replica data on behaviour (with caching probably).\n",
    "\n",
    "## Note\n",
    "1. the thanker final data collector was written in the edit-sync repo as part of onboard_thankers. I'm switching it up because this is closer to the goal of making a dataCollector module for civilservant2.0\n",
    "\n",
    "### connections\n",
    "1. connecting to aws studies mysql on `3311`\n",
    "    1. `ssh -N studies.cs 3311:localhost:3306`\n",
    "2. connecting to wmf repliacs on `3310`\n",
    "    1. `ssh -N maximilianklein@tools-login.wmflabs.org -L 3310:enwiki.analytics.db.svc.eqiad.wmflabs:3306`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from civilservant.models.core import ExperimentThing, ExperimentAction\n",
    "from thanks.utils import _get_experiment_id\n",
    "from civilservant.util import read_config_file\n",
    "import os\n",
    "from civilservant.db import init_session, init_engine\n",
    "from sqlalchemy.dialects import mysql\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import uuid\n",
    "CACHEDIR='/data/project/cache'\n",
    "TRESORDIR='/home/paprika/Tresors/CivilServant/projects/wikipedia-integration/gratitude-study/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(CACHEDIR, 'thankee-misc', 'survey_and_thankee_actions.pickle'))\n",
    "acct_map = pd.read_pickle(os.path.join(CACHEDIR, 'thankee-misc', 'acct_map.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assign behavioral_obs_start_dt \n",
    "1. based on first_thank_dt or that of block partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_block_id = df['randomization_block_id']>=0\n",
    "non_null_thank_dt = pd.notnull(df['first_thank_dt'])\n",
    "\n",
    "block_thank_rel = df[(positive_block_id) & (non_null_thank_dt)][['randomization_block_id', 'first_thank_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_first_thank = block_thank_rel.set_index('randomization_block_id').to_dict()['first_thank_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_start_dt(row):\n",
    "    # if we have a thank date use that\n",
    "    if pd.notnull(row.loc['first_thank_dt']):\n",
    "        return row.loc['first_thank_dt']\n",
    "    # otherwise do they have a block partner with a first thank date\n",
    "    else:\n",
    "        try:\n",
    "            return block_first_thank[row.loc['randomization_block_id']]\n",
    "        # fallback onto the ET created date\n",
    "        except KeyError:\n",
    "            return row.loc['created_dt']\n",
    "\n",
    "df['behavior_start_dt'] = df.apply(lambda row: get_behavior_start_dt(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any(pd.isnull(df['behavior_start_dt'])) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting external data\n",
    "\n",
    "1. labor.hours.per.day.diff \n",
    "    1. participants$labor.hours.per.day.post.treatment -participants$labor.hours.per.day.pre.treatment\n",
    "    2. 42 days before and after the thank\n",
    "2. two.week.retention\n",
    "    1. Whether an account made an edit any-namespace between day 8 and 42 after they received a thank\n",
    "3. thanks.sent\n",
    "    1. count variable indicating the number of thanks sent by this account to other Wikipedians in the 42 day period after receiving the intervention.\n",
    "4. registration date\n",
    "    1. account age at created_dt\n",
    "    1. account age at first_thank_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from civilservant.wikipedia.queries.revisions import get_timestamps_within_range\n",
    "from civilservant.wikipedia.queries.user_interactions import get_thanks_sending\n",
    "from civilservant.wikipedia.queries.users import get_user_basic_data, get_user_disablemail_property\n",
    "from civilservant.wikipedia.utils import make_cached_df, make_sessions, calc_labour_hours,\\\n",
    "                                            to_wmftimestamp, from_wmftimestamp, bin_from_td\n",
    "from civilservant.wikipedia.connections.database import make_wmf_con\n",
    "\n",
    "wmf_con = make_wmf_con()\n",
    "\n",
    "LABOR_HOURS_OBS_WINDOW = datetime.timedelta(days=42)\n",
    "\n",
    "@make_cached_df('grat-thankee-timestamps')\n",
    "def get_user_edits_before_and_after_obs(lang, user_name, thank_date):\n",
    "    start_date = thank_date - LABOR_HOURS_OBS_WINDOW\n",
    "    end_date = thank_date + LABOR_HOURS_OBS_WINDOW\n",
    "    ts = get_timestamps_within_range(lang=lang, start_date=start_date, end_date=end_date, user_name=user_name,\n",
    "                         con=wmf_con)\n",
    "    return ts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frem length: 15958\n"
     ]
    }
   ],
   "source": [
    "# delete this for full run\n",
    "# df = df[:1000]\n",
    "print(f'data frem length: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_hours_ts_df'] = df.apply(lambda row: get_user_edits_before_and_after_obs(row['lang'],\n",
    "                                                                                  row['user_name'],\n",
    "                                                                                  row['behavior_start_dt'])\n",
    "                                                                                   , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labor_hours(before_after, behavior_start_dt, ts_df):\n",
    "    start_dt = behavior_start_dt - LABOR_HOURS_OBS_WINDOW if before_after=='before' else behavior_start_dt\n",
    "    end_dt = behavior_start_dt if before_after=='before' else behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    \n",
    "    window_ts_df =  ts_df[(ts_df['rev_timestamp'] > start_dt)  & (ts_df['rev_timestamp'] <= end_dt)]\n",
    "    if len(window_ts_df)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        window_dts = [pd.to_datetime(np_dt) for np_dt in window_ts_df['rev_timestamp'].values]\n",
    "        window_labor_hours = calc_labour_hours(window_dts)\n",
    "        return window_labor_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_hours_pre_treatment'] = df.apply(lambda row: num_labor_hours('before', \n",
    "                                                                row['behavior_start_dt'],\n",
    "                                                                row['labor_hours_ts_df']),\n",
    "                                    axis=1)\n",
    "df['labor_hours_post_treatment'] = df.apply(lambda row: num_labor_hours('after', \n",
    "                                                                row['behavior_start_dt'],\n",
    "                                                                row['labor_hours_ts_df']),\n",
    "                                    axis=1)\n",
    "\n",
    "df['labor_hours_per_day_pre_treatment'] = df['labor_hours_pre_treatment'] / LABOR_HOURS_OBS_WINDOW.days\n",
    "df['labor_hours_per_day_post_treatment'] = df['labor_hours_post_treatment'] / LABOR_HOURS_OBS_WINDOW.days\n",
    "df['labor_hours_per_day_diff'] = df['labor_hours_per_day_post_treatment'] - df['labor_hours_per_day_pre_treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006875556188831662"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labor_hours_per_day_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_week_retention(behavior_start_dt, ts_df):\n",
    "    start_dt = behavior_start_dt + datetime.timedelta(days=7)\n",
    "    end_dt = behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    \n",
    "    window_ts_df =  ts_df[(ts_df['rev_timestamp'] > start_dt)  & (ts_df['rev_timestamp'] <= end_dt)]\n",
    "    return True if len(window_ts_df)>0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['two_week_retention'] = df.apply(lambda row: two_week_retention(row['behavior_start_dt'],\n",
    "                                                                   row['labor_hours_ts_df']),\n",
    "                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2507206416844216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['two_week_retention'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankees-thanks-sent')\n",
    "def get_subsequent_thanks_sent(lang, user_name, behavior_start_dt):\n",
    "    start_dt = behavior_start_dt\n",
    "    end_dt = behavior_start_dt + LABOR_HOURS_OBS_WINDOW\n",
    "    thanks_sent = get_thanks_sending(lang, user_name, start_dt, end_dt, wmf_con)\n",
    "    return thanks_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thanks_sent_df'] = df.apply(lambda row: get_subsequent_thanks_sent(row['lang'],\n",
    "                                                                    row['user_name'],\n",
    "                                                                    row['behavior_start_dt'],                                                                   ),\n",
    "                                    axis=1)\n",
    "df['thanks_sent'] = df['thanks_sent_df'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16299034966787818"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thanks_sent'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankee-user-basic-data')\n",
    "def get_user_basic(lang, user_name):\n",
    "    return get_user_basic_data(lang=lang, user_name=user_name, wmf_con=wmf_con)\n",
    "\n",
    "def user_registration_dt_from_basic(user_basic_df):\n",
    "    return user_basic_df['user_registration'].iloc[0] if len(user_basic_df)>0 else float('nan')\n",
    "\n",
    "def user_id_from_basic(user_basic_df):\n",
    "    return user_basic_df['user_id'].iloc[0] if len(user_basic_df)>0 else float('nan')\n",
    "\n",
    "def account_age_at_assignment(created_dt, registration_dt):\n",
    "    return bin_from_td(created_dt-registration_dt) if pd.notnull(registration_dt) else registration_dt\n",
    "\n",
    "def account_age_at_treatment(behavior_start_dt, registration_dt):\n",
    "    return bin_from_td(behavior_start_dt-registration_dt) if pd.notnull(registration_dt) else registration_dt\n",
    "\n",
    "def year(registration_dt):\n",
    "    return registration_dt.year if pd.notnull(registration_dt) else registration_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_basic_data'] = df.apply(lambda row: get_user_basic(row['lang'], row['user_name']), axis=1)\n",
    "\n",
    "df['user_registration_dt'] = df['user_basic_data'].apply(user_registration_dt_from_basic)\n",
    "df['user_id'] = df['user_basic_data'].apply(user_id_from_basic)\n",
    "\n",
    "df['prev_experience_assignment'] = df.apply(lambda row: account_age_at_assignment(row['created_dt'], row['user_registration_dt']) ,axis=1)\n",
    "df['prev_experience_treatment'] = df.apply(lambda row: account_age_at_assignment(row['behavior_start_dt'], row['user_registration_dt']) ,axis=1)\n",
    "\n",
    "df['year'] = df['user_registration_dt'].apply(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_cached_df('grat-thankee-has-email')\n",
    "def get_has_disablemail_df(lang, user_id):\n",
    "    disablemail_df = get_user_disablemail_property(lang, user_id, wmf_con=wmf_con)\n",
    "    return disablemail_df # True if they havent disabled, otherwise they have disabled and dont get email\n",
    "    \n",
    "def get_has_email(lang, user_id):\n",
    "    if pd.isnull(user_id):\n",
    "        return user_id\n",
    "    else:\n",
    "        disablemail_df = get_has_disablemail_df(lang, user_id)\n",
    "        return True if len(disablemail_df)==0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_email'] = df.apply(lambda row: get_has_email(row['lang'], row['user_id']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compliance - app\n",
    "1. noncompliant if don't have a user_registration_date\n",
    "2. block partners of removed users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15958, 42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thanks_not_received_skipped']  = (pd.isnull(df['first_thank_dt'])) & (df['num_skips'] > 0) \n",
    "df['thanks_not_received_not_seen'] = (pd.isnull(df['first_thank_dt'])) & (df['num_skips'] == 0) & (df['num_errors']==0)\n",
    "df['thanks_not_received_error']  = (pd.isnull(df['first_thank_dt'])) & (df['num_errors'] > 0)\n",
    "df['thanks_not_received_user_deleted'] = df['user_basic_data'].apply(len) == 0\n",
    "df['received_multiple_thanks'] = df['num_thanks'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complier_app_any_reason'] = ~(df['thanks_not_received_skipped'] | df['thanks_not_received_not_seen'] | df['thanks_not_received_error'] | df['thanks_not_received_user_deleted'] | df['received_multiple_thanks'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compliance Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complier'] = pd.notnull(df['wikipedians.value.contributions']) & pd.notnull(df['community.friendly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_COLS = [\n",
    "'private.anonymous.id',\n",
    "'randomization.block.id',\n",
    "'labor.hours.per.day.diff', \n",
    "'two.week.retention',\n",
    "'thanks.sent',\n",
    "'wikipedians.value.contributions',\n",
    "'community.friendly',\n",
    "'complier',\n",
    "'lang',\n",
    "'prev.experience.assignment',\n",
    "'prev.experience.treatment',\n",
    "'year',\n",
    "'has.email',\n",
    "'remembered.thanks',\n",
    "'overall.exp',    \n",
    "'social.value.1',    \n",
    "'social.value.3',    \n",
    "'social.value.4',    \n",
    "'social.warmth.2',    \n",
    "'social.warmth.3',    \n",
    "'randomization.arm',\n",
    "'number.thanks.received',\n",
    "'number.skips.received',\n",
    "'thanks.not.received.skipped',\n",
    "'thanks.not.received.not.seen',\n",
    "'thanks.not.received.error',\n",
    "'thanks.not.received.user.deleted',\n",
    "'received.multiple.thanks', \n",
    "'complier.app.any.reason', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_dt', 'randomization_arm', 'randomization_condition',\n",
       "       'removed_dt', 'metadata_json', 'lang', 'user_name',\n",
       "       'randomization_block_id', 'num_errors', 'num_skips', 'first_thank_dt',\n",
       "       'num_thanks', 'num_messages', 'consent', 'overall.exp',\n",
       "       'social.value.1', 'wikipedians.value.contributions', 'social.value.3',\n",
       "       'social.value.4', 'community.friendly', 'social.warmth.2',\n",
       "       'social.warmth.3', 'community', 'remembered.thanks',\n",
       "       'private_anonymous_id', 'behavior_start_dt', 'labor_hours_ts_df',\n",
       "       'labor_hours_pre_treatment', 'labor_hours_post_treatment',\n",
       "       'labor_hours_per_day_pre_treatment',\n",
       "       'labor_hours_per_day_post_treatment', 'labor_hours_per_day_diff',\n",
       "       'two_week_retention', 'thanks_sent_df', 'thanks_sent',\n",
       "       'user_basic_data', 'user_registration_dt', 'user_id',\n",
       "       'prev_experience_assignment', 'prev_experience_treatment', 'year',\n",
       "       'has_email', 'thanks_not_received_skipped',\n",
       "       'thanks_not_received_not_seen', 'thanks_not_received_error',\n",
       "       'thanks_not_received_user_deleted', 'received_multiple_thanks',\n",
       "       'complier_app_any_reason', 'complier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_col_names = [cname.replace('_','.') for cname in df.columns]\n",
    "df.columns = r_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rename = {'num.skips':'number.skips.received',\n",
    "             'num.thanks':'number.thanks.received'}\n",
    "df = df.rename(columns=col_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_col_present = [oc in df.columns for oc in OUTPUT_COLS]\n",
    "all(output_col_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('private.anonymous.id', True),\n",
       " ('randomization.block.id', True),\n",
       " ('labor.hours.per.day.diff', True),\n",
       " ('two.week.retention', True),\n",
       " ('thanks.sent', True),\n",
       " ('wikipedians.value.contributions', True),\n",
       " ('community.friendly', True),\n",
       " ('complier', True),\n",
       " ('lang', True),\n",
       " ('prev.experience.assignment', True),\n",
       " ('prev.experience.treatment', True),\n",
       " ('year', True),\n",
       " ('has.email', True),\n",
       " ('remembered.thanks', True),\n",
       " ('overall.exp', True),\n",
       " ('social.value.1', True),\n",
       " ('social.value.3', True),\n",
       " ('social.value.4', True),\n",
       " ('social.warmth.2', True),\n",
       " ('social.warmth.3', True),\n",
       " ('randomization.arm', True),\n",
       " ('number.thanks.received', True),\n",
       " ('number.skips.received', True),\n",
       " ('thanks.not.received.skipped', True),\n",
       " ('thanks.not.received.not.seen', True),\n",
       " ('thanks.not.received.error', True),\n",
       " ('thanks.not.received.user.deleted', True),\n",
       " ('received.multiple.thanks', True),\n",
       " ('complier.app.any.reason', True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(OUTPUT_COLS, output_col_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Data Drills'\t'research materials'\t    thanks_love_counts_2017\r\n",
      " datasets\t thankable_revisions_task   thanks-love-records-07.2018\r\n",
      "'gdpr notices'\t thanker_surveys\r\n",
      " report-drafts\t thanking_paper_prototype\r\n"
     ]
    }
   ],
   "source": [
    "!ls $TRESORDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'Data Drills/thankee/post_experiment_analysis'\n",
    "out_fname = 'grat-thankee-all-pre-post-treatment-vars.csv'\n",
    "acct_map.to_csv(os.path.join(TRESORDIR, out_dir,'acct_map.csv'), index=False)\n",
    "df[OUTPUT_COLS].to_csv(os.path.join(TRESORDIR, out_dir, out_fname), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
